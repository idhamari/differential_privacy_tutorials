{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idhamari/differential_privacy_tutorials/blob/main/DP_Attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About:\n",
        "\n",
        "\n",
        "In these tutorial, I will try to explain Differential Privacy (DP) in a practical way with examples using simple python scripts. I will try to add more details, examples, and scripts whenever i find the time, so please consider this work in progress.\n",
        "\n",
        "Resources:\n",
        "\n"
      ],
      "metadata": {
        "id": "i-oKsY5MCoPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Data Privacy:\n",
        "\n",
        "**Data privacy** is the concept that refers to the protection and management of personal or sensitive information to ensure that it remains confidential, secure, and used appropriately. With the increasing digitization and collection of vast amounts of data, data privacy has become a critical concern for individuals, organizations, and governments. It encompasses the ethical and legal considerations surrounding the collection, storage, sharing, and usage of personal data.\n",
        "\n",
        "In today's interconnected world, where data is collected from various sources such as social media platforms, online transactions, healthcare records, and IoT devices, maintaining data privacy is challenging. Protecting personal information is crucial as it includes details like names, addresses, financial records, health information, and other sensitive attributes that can be misused or exploited if not adequately safeguarded.\n",
        "\n",
        "**Real-Life Examples: The Limitations of Removing Names and Fields**\n",
        "\n",
        "Removing names and certain identifiable fields from datasets has been a common practice to protect privacy. However, this approach alone is often insufficient to guarantee privacy due to the following reasons:\n",
        "\n",
        "1. **Re-identification Attacks:** Even when names and directly identifiable information are removed, attackers can use various techniques to re-identify individuals. For instance, by cross-referencing multiple datasets or combining publicly available information, an attacker can match unique attributes to re-identify individuals. The Netflix Prize dataset release in 2006 was an example where researchers were able to re-identify individuals by linking the movie ratings dataset with other publicly available information.\n",
        "\n",
        "2. **Attribute Inference:** Even if explicit identifiers are removed, sensitive attributes can still be inferred by analyzing other non-identifiable fields. By leveraging patterns or correlations within the data, attackers can deduce sensitive information about individuals. For instance, a study published in 2009 demonstrated that individuals' sexual orientation could be inferred with high accuracy by analyzing their social network connections, even when explicit identifiers were not present.\n",
        "\n",
        "3. **Statistical Disclosure:** Aggregated or anonymized datasets can still contain statistical patterns that enable attackers to deduce sensitive information about individuals. Researchers have shown that by applying advanced statistical analysis techniques, individuals' private information, such as medical conditions or financial status, can be inferred from seemingly anonymized data.\n",
        "\n",
        "4. **Contextual Information:** Even when explicit identifiers are removed, contextual information present in the dataset can aid in re-identification. For example, a combination of location, occupation, and age may uniquely identify an individual within a specific region or profession, even if their name is not present.\n",
        "\n",
        "These examples illustrate that merely removing names and identifiable fields from datasets is not sufficient to ensure data privacy. It is essential to adopt more comprehensive approaches, such as data anonymization techniques, encryption, differential privacy, and rigorous access controls, to safeguard individuals' privacy and protect against privacy attacks.\n",
        "\n",
        "Data privacy regulations, such as the **General Data Protection Regulation (GDPR)** in Europe and the **California Consumer Privacy Act (CCPA)** in the United States, emphasize the need for organizations to implement robust privacy measures and obtain informed consent from individuals when handling their personal data. These regulations aim to strike a balance between data utility and privacy protection, encouraging organizations to implement privacy-enhancing practices to mitigate the risks associated with data privacy breaches.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_wmnTO8hocVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  popular types of privacy attacks.\n",
        "\n",
        "\n",
        "* **Membership Inference Attack (MIA):** This attack aims to determine whether a particular individual's record is present in a dataset without revealing the specific information of the individual. This technique poses a significant threat to privacy, especially in scenarios where sensitive information is stored or shared.\n",
        "\n",
        "* **Attribute Inference Attack:** This attack aims to infer sensitive attributes or characteristics of individuals based on available non-sensitive attributes. For example, inferring a person's salary based on their occupation, education level, and geographic location.\n",
        "\n",
        "* **Reconstruction Attack:** Reconstruction attacks attempt to reconstruct the original data or sensitive information from aggregated or anonymized data. These attacks exploit vulnerabilities in data anonymization techniques and re-identify individuals based on unique combinations of attributes.\n",
        "\n",
        "* **Linkage Attack:** Linkage attacks involve linking multiple datasets or combining publicly available information to identify individuals in a dataset that is presumed to be anonymous. By matching common identifiers or attributes, an attacker can re-identify individuals and uncover sensitive information.\n",
        "\n",
        "* **Timing Attack:** Timing attacks exploit variations in response times or resource consumption to infer sensitive information. For example, in a web application, an attacker can measure the time it takes to respond to different queries and deduce information about the underlying data or operations being performed.\n",
        "\n",
        "* **Side-Channel Attack:** Side-channel attacks leverage information leaked through unintended channels such as power consumption, electromagnetic radiation, or network traffic. These attacks target the physical implementation of a system to extract sensitive information, rather than directly targeting the data itself.\n",
        "\n",
        "* **Differential Privacy Attack:** Differential privacy attacks focus on bypassing or exploiting the privacy guarantees provided by differential privacy mechanisms. By analyzing multiple queries or responses, an attacker can gain insights into the sensitive data or individuals.\n",
        "\n",
        "* **Homomorphic Encryption Attack:** Homomorphic encryption attacks involve exploiting weaknesses or vulnerabilities in homomorphic encryption schemes to reveal sensitive data. These attacks target the encryption and decryption processes and aim to bypass the privacy protection provided by homomorphic encryption.\n",
        "\n",
        "It's important to note that these attacks highlight the need for robust privacy protection mechanisms and practices. Data anonymization, differential privacy techniques, secure data handling, and encryption play a crucial role in safeguarding individuals' privacy and mitigating the risks associated with these attacks."
      ],
      "metadata": {
        "id": "gVJWC79CA_Vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Membership Inference Attack (MIA):\n",
        "\n",
        "These attacks are a type of privacy attack that aims to determine whether a particular individual's record is present in a dataset without revealing the specific information of the individual. This technique poses a significant threat to privacy, especially in scenarios where sensitive information is stored or shared. In this tutorial, we will explore the concept of membership attacks and demonstrate a Python example to understand how they can be implemented.\n",
        "\n",
        "**Understanding Membership Attacks:**\n",
        "\n",
        "A membership attack, also known as a membership inference attack, attempts to determine if a specific record or individual is present in a dataset by exploiting the statistical properties of the dataset. These attacks can be launched against machine learning models that have been trained on sensitive data or contain personal information. The primary goal is to extract sensitive information without directly accessing it, thereby compromising the privacy of individuals.\n",
        "\n",
        "**Example - Membership Attack on a Dataset:**\n",
        "\n",
        "Assuming we have a dataset.\n",
        "\n",
        "First, we create a machine learning model to represent the dataset.   \n",
        "Then we use the model to check if a record is available in the dataset by getting the label with some accuracy. if the acuracy is high then the record is included, if not then it is not.     \n",
        "\n",
        "    \n",
        "**Conclusion:**\n",
        "Membership attacks are a serious privacy concern, and understanding their concepts and implications is crucial for data privacy protection. By exploiting the statistical properties of a dataset, attackers can determine if specific records or individuals are part of the dataset. Organizations and data practitioners should be aware of the risks associated with membership attacks and employ appropriate privacy-preserving techniques to safeguard sensitive information.\n",
        "\n",
        "Remember that respecting privacy and following ethical guidelines should be a priority when dealing with sensitive data.\n"
      ],
      "metadata": {
        "id": "9BruRknAq-gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import urllib\n",
        "import random\n",
        "\n",
        "\n",
        "def getData():\n",
        "    # Download the Adult dataset from UCI Machine Learning Repository\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "    filename = \"adult.csv\"\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "    # Load the Adult dataset\n",
        "    data = pd.read_csv('adult.csv', header=None)\n",
        "\n",
        "    # Assign column names to the dataset\n",
        "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
        "                    'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss',\n",
        "                    'hours_per_week', 'native_country', 'label']\n",
        "    data.columns = column_names\n",
        "\n",
        "    # Perform one-hot encoding for categorical features\n",
        "    categorical_features = ['workclass', 'education', 'marital_status', 'occupation',\n",
        "                            'relationship', 'race', 'sex', 'native_country']\n",
        "    data_encoded = pd.get_dummies(data, columns=categorical_features)\n",
        "    return data_encoded\n",
        "\n",
        "def getTrainedModel(data_encoded, test_size=0.2,random_state=42, modelID=\"RandomForestClassifier\"):\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    train_data, test_data = train_test_split(data_encoded, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Separate features and labels\n",
        "    train_features = train_data.drop('label', axis=1)\n",
        "    train_labels = train_data['label']\n",
        "    test_features = test_data.drop('label', axis=1)\n",
        "    test_labels = test_data['label']\n",
        "\n",
        "    # Train a machine learning model on the training set\n",
        "    model = None\n",
        "    if modelID==\"RandomForestClassifier\":\n",
        "       model = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
        "\n",
        "    model.fit(train_features, train_labels)\n",
        "\n",
        "    # Evaluate the model on the testing set\n",
        "    test_predictions = model.predict(test_features)\n",
        "    test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "    return model, test_features, test_labels, test_accuracy\n",
        "\n",
        "def getSampleAttackData(target_data, target_labels, isMember=1):\n",
        "    if isMember:\n",
        "        attack_data = target_data.sample(n=1)\n",
        "        attack_labels = target_labels.sample(n=1)\n",
        "    else:\n",
        "        # Generate random data of the same type\n",
        "        attack_data =pd.DataFrame([[random.random() for x in range(len(target_data.columns))]], columns=  list(target_data.columns))\n",
        "        attack_labels = pd.Series([random.choice(['<=50K','>50K'])])\n",
        "\n",
        "    return attack_data, attack_labels\n",
        "\n",
        "# Perform membership inference attack\n",
        "def checkMembership(model, attack_data, attack_labels ):\n",
        "\n",
        "    # Make predictions on the attack data\n",
        "    attack_predictions = model.predict(attack_data)\n",
        "    attack_predictions= attack_predictions[0]\n",
        "    attack_labels=list(attack_labels)[0]\n",
        "\n",
        "    # # Calculate the accuracy of the membership inference attack\n",
        "    attack_result = (attack_predictions == attack_labels)\n",
        "    return  attack_result\n",
        "\n",
        "print(\"=============  Membership Attack Example ================\")\n",
        "random_state = 42\n",
        "\n",
        "# Get sample data, we are using USA adult dataset (32561 rows and 109 attributes)\n",
        "data_encoded = getData()\n",
        "\n",
        "\n",
        "# get trained model\n",
        "model, test_features, test_labels, test_accuracy = getTrainedModel(data_encoded, test_size=0.01,random_state=42, modelID=\"RandomForestClassifier\")\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# create sample data to attack (we either generate a record for a member person or non member person)\n",
        "isMember     = 0\n",
        "attack_data, attack_labels =  getSampleAttackData(test_features, test_labels, isMember=isMember)\n",
        "\n",
        "# Perform the membership inference attack on the trained model using the sample attack data\n",
        "print(\"testing using isMember              : \", isMember)\n",
        "print(f'Membership Inference Attack Accuracy: {checkMembership(model, attack_data, attack_labels)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8_i2PfPocne",
        "outputId": "96ab1cba-f158-4e4f-ed84-0c82c3a4031d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============  Membership Attack Example ================\n",
            "Test Accuracy: 0.8895705521472392\n",
            "testing using isMember              :  0\n",
            "Membership Inference Attack Accuracy: False\n"
          ]
        }
      ]
    }
  ]
}